{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPa_jUsscTiH"
   },
   "source": [
    "## Finding ProteinMPNN Relevant Code\n",
    "\n",
    "Preparing simplified functions from the PMPNN script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "V9XVHUwMcTiL",
    "outputId": "6d0edeb1-7169-41c0-b96c-8e2dd1e8e35f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from collections import namedtuple\n",
    "\n",
    "from ProteinMPNN.protein_mpnn_utils import tied_featurize, parse_PDB, parse_fasta, _scores\n",
    "from ProteinMPNN.protein_mpnn_utils import StructureDatasetPDB, ProteinMPNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFryytrecTiO"
   },
   "source": [
    "#### Scoring code\n",
    "\n",
    "Input:\n",
    "    pdb_path\n",
    "    fasta_path (optional)\n",
    "\n",
    "Output:\n",
    "    logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dzDYImd9cTiQ"
   },
   "outputs": [],
   "source": [
    "#arguments\n",
    "class Arguments():\n",
    "    def __init__(self,\n",
    "                 pdb_path: str, # Path to a single PDB to be designed\n",
    "                 fasta_path: str=\"\", # Path to file containing one sequence to be scored in fasta format - currently incompatible with multiple sequences\n",
    "                 ca_only: bool=False, # Parse CA-only structures and use CA-only models\n",
    "                 backbone_noise: float=0, # Standard deviation of Gaussian noise to add to backbone atoms\n",
    "                 max_length: int=200000, # Max sequence length\n",
    "                 model_path: str='ProteinMPNN/vanilla_model_weights/v_48_020.pt' # Path to model weights folder\n",
    "                ):\n",
    "\n",
    "        self.pdb_path = pdb_path\n",
    "        self.fasta_path = fasta_path\n",
    "        self.ca_only = ca_only\n",
    "        self.backbone_noise = backbone_noise\n",
    "        self.max_length = max_length\n",
    "        self.model_path = model_path\n",
    "\n",
    "# args = Arguments(pdb_path=\"examples/pdbs/5L33.pdb\",\n",
    "#                  fasta_path=\"examples/fastas/5L33-mut_seq.fasta\")\n",
    "# args = Arguments(pdb_path=\"examples/pdbs/6MRR.pdb\",\n",
    "#                  fasta_path=\"examples/fastas/6MRR-mut_seq.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmpnn_score_pdb_seq(args):\n",
    "    \n",
    "    #data objects to initialize\n",
    "    alphabet = 'ACDEFGHIKLMNPQRSTVWYX'\n",
    "    alphabet_dict = dict(zip(alphabet, range(21)))\n",
    "    \n",
    "    \n",
    "    # initialize the model\n",
    "    device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "    ## load the checkpoint\n",
    "    checkpoint = torch.load(args.model_path, map_location=device)\n",
    "\n",
    "    hidden_dim = 128\n",
    "    num_layers = 3\n",
    "\n",
    "    model = ProteinMPNN(ca_only=args.ca_only,\n",
    "                        num_letters=21,\n",
    "                        node_features=hidden_dim,\n",
    "                        edge_features=hidden_dim,\n",
    "                        hidden_dim=hidden_dim,\n",
    "                        num_encoder_layers=num_layers,\n",
    "                        num_decoder_layers=num_layers,\n",
    "                        augment_eps=args.backbone_noise,\n",
    "                        k_neighbors=checkpoint['num_edges'])\n",
    "    \n",
    "    \n",
    "    # prepare pdb input for tied_featurize: sequence, coordinates, metadata extracted from pdb and saved to dict\n",
    "    pdb_dict_list = parse_PDB(args.pdb_path, ca_only=args.ca_only)\n",
    "    dataset_valid = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=args.max_length)\n",
    "\n",
    "    batch_clones = [dataset_valid[0]] # if only one pdb passed as input and batch size = 1\n",
    "    \n",
    "    \n",
    "    # load variables to pass to model to get log_probs\n",
    "    tf_output = tied_featurize(batch=batch_clones,\n",
    "                               device=device,\n",
    "                               chain_dict=None,\n",
    "                               fixed_position_dict=None,\n",
    "                               omit_AA_dict=None,\n",
    "                               tied_positions_dict=None,\n",
    "                               pssm_dict=None,\n",
    "                               bias_by_res_dict=None,\n",
    "                               ca_only=args.ca_only)\n",
    "\n",
    "    ## save return (20 outputs) to named tuple\n",
    "    tfOutputTuple = namedtuple(\"tfOutputTuple\", [\"X\", \"S\", \"mask\", \"lengths\", \"chain_M\",\n",
    "                                                 \"chain_encoding_all\", \"chain_list_list\",\n",
    "                                                 \"visible_list_list\", \"masked_list_list\",\n",
    "                                                 \"masked_chain_length_list_list\", \"chain_M_pos\",\n",
    "                                                 \"omit_AA_mask\", \"residue_idx\", \"dihedral_mask\",\n",
    "                                                 \"tied_pos_list_of_lists_list\", \"pssm_coef\",\n",
    "                                                 \"pssm_bias\", \"pssm_log_odds_all\", \"bias_by_res_all\",\n",
    "                                                 \"tied_beta\"])\n",
    "    tf = tfOutputTuple(*tf_output)\n",
    "    \n",
    "    \n",
    "    # read in sequence from fasta if given\n",
    "    if args.fasta_path:\n",
    "        fasta_names, fasta_seqs = parse_fasta(args.fasta_path, omit=[\"/\"])\n",
    "        assert len(fasta_seqs) == 1 ## currently only compatible with one pdb in, one pdb out\n",
    "        fasta_seq = fasta_seqs[0]\n",
    "        input_seq_length = len(fasta_seq)\n",
    "\n",
    "        # update tf.S to be input sequence – otherwise is sequence read from pdb\n",
    "        S_input = torch.tensor([alphabet_dict[AA] for AA in fasta_seq], device=device)[None,:].repeat(tf.X.shape[0], 1)\n",
    "        tf.S[:,:input_seq_length] = S_input #assumes that S and S_input are alphabetically sorted for masked_chains\n",
    "\n",
    "    ## TO DO: compatability with scoring multiple sequences\n",
    "\n",
    "    \n",
    "    # score sequence for pdb (log probs)\n",
    "    randn_1 = torch.randn(tf.chain_M.shape, device=tf.X.device)\n",
    "    # get log probs\n",
    "    log_probs = model(tf.X, tf.S, tf.mask, tf.chain_M*tf.chain_M_pos, tf.residue_idx, tf.chain_encoding_all, randn_1)\n",
    "    mask_for_loss = tf.mask*tf.chain_M*tf.chain_M_pos\n",
    "    scores = _scores(tf.S, log_probs, mask_for_loss)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.5213], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scoring pdb given a sequence\n",
    "pmpnn_score_pdb_seq(args=Arguments(pdb_path=\"examples/pdbs/5L33.pdb\",\n",
    "                    fasta_path=\"examples/fastas/5L33-mut_seq.fasta\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.0384], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scoring pdb given a sequence\n",
    "pmpnn_score_pdb_seq(args=Arguments(pdb_path=\"examples/pdbs/6MRR.pdb\",\n",
    "                    fasta_path=\"examples/fastas/6MRR-mut_seq.fasta\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.4667], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scoring pdb given no sequence – score sequence in pdb\n",
    "pmpnn_score_pdb_seq(args=Arguments(pdb_path=\"examples/pdbs/5L33.pdb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.5551], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scoring pdb given no sequence – score sequence in pdb\n",
    "pmpnn_score_pdb_seq(args=Arguments(pdb_path=\"examples/pdbs/6MRR.pdb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
